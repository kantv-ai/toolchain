# toolchain
this repo provide customized WoA toolchain for [project llama.cpp](https://github.com/ggml-org/llama.cpp), the idea comes from:https://github.com/ggml-org/llama.cpp/pull/12215


llvm-mingw-20250305-ggml-ucrt-x86_64.zip: build llama.cpp for target WoA(Windows on ARM) on x86-64 Windows without huge VS2022 IDE(about 19G), size of this file is about 234M.
